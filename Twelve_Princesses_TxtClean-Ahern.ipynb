{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize   #split words from punct\n",
    "from nltk.tokenize import sent_tokenize   #split sentences from punct\n",
    "from nltk.tokenize import TweetTokenizer   #break apart content into it's most meaningful aspects\n",
    "from nltk.probability import FreqDist   # how many of a particular word there are\n",
    "from nltk.corpus import stopwords      #for removing filler words\n",
    "from nltk.stem import WordNetLemmatizer    #take a word and turn it into it's base dictionary form\n",
    "from string import punctuation           #sample data - list of puncuation marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment: Read the file and use the NLTK library to tokenize each word in the text. \n",
    "            After using that code to load and tokenizing each word, then remove the punctuation and filler words (stopwords) \n",
    "            from the list of tokens. Lastly, get the top 10 words from the text."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# download packages below one time ever and then change cell to raw\n",
    "# VADER: Valence Aware Dictionary and sEntiment Reasoner\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('names')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in text file 12dancingprincesses.txt\n",
    "\n",
    "with open('12dancingprincesses.txt', 'r') as file:\n",
    "    prncss_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prncss_text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change all words to lower case\n",
    "prncss_text = prncss_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize each part of the text\n",
    "prncss_wtk = word_tokenize(prncss_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at first fifteen tokens in list\n",
    "prncss_wtk[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 10 words in text as of now\n",
    "fd_ct = FreqDist(prncss_wtk)\n",
    "fd_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The most common parts of text are filler and punctuation. First remove punctuation for better understanding of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of tokens before punctuation removal\n",
    "len(prncss_wtk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = punctuation + '’' + '‘' + '’’' + '‘‘'\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation tokens from list\n",
    "for token in prncss_wtk:\n",
    "    if token in punctuation:\n",
    "        prncss_wtk.remove(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of tokens after punctuation removal\n",
    "len(prncss_wtk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation tokens from list again\n",
    "for token in prncss_wtk:\n",
    "    if token in punctuation:\n",
    "        prncss_wtk.remove(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of tokens after total punctuation removal\n",
    "len(prncss_wtk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 10 words in text as of now\n",
    "fd_ct = FreqDist(prncss_wtk)\n",
    "fd_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove english stop words from list\n",
    "eng_stopwords = stopwords.words('english')\n",
    "\n",
    "rm_count = 0\n",
    "prncss_new = []  #list to hold new words\n",
    "\n",
    "for token in prncss_wtk:\n",
    "    if token not in eng_stopwords:\n",
    "        prncss_new.append(token)\n",
    "    else: rm_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"removal count = {rm_count}\")\n",
    "print(f\"final list length = {len(prncss_new)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 words in text after tokenizing, punctuation removal, and stop words removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 words in text after tokenizing, punctuation removal, and stop words removal.\n",
    "fd_ct = FreqDist(prncss_new)\n",
    "fd_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
