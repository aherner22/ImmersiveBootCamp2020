{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize   #split words from punct\n",
    "#from nltk.tokenize import sent_tokenize   #split sentences from punct\n",
    "#from nltk.tokenize import TweetTokenizer   #break apart content into it's most meaningful aspects\n",
    "from nltk.probability import FreqDist   # how many of a particular word there are\n",
    "from nltk.corpus import stopwords      #for removing filler words\n",
    "#from nltk.stem import WordNetLemmatizer    #take a word and turn it into it's base dictionary form\n",
    "from string import punctuation           #sample data - list of puncuation marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment: Read the file and use the NLTK library to tokenize each word in the text. \n",
    "            After using that code to load and tokenizing each word, then remove the punctuation and filler words (stopwords) \n",
    "            from the list of tokens. Lastly, get the top 10 words from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in text file 12dancingprincesses.txt\n",
    "\n",
    "with open('12dancingprincesses.txt', 'r') as file:\n",
    "    prncss_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE TWELVE DANCING PRINCESSES\\n\\nThere was a king wh'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prncss_text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change all words to lower case\n",
    "prncss_text = prncss_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize each part of the text\n",
    "prncss_wtk = word_tokenize(prncss_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'twelve',\n",
       " 'dancing',\n",
       " 'princesses',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'king',\n",
       " 'who',\n",
       " 'had',\n",
       " 'twelve',\n",
       " 'beautiful',\n",
       " 'daughters',\n",
       " '.',\n",
       " 'they']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at first fifteen tokens in list\n",
    "prncss_wtk[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 139, ',': 102, 'and': 78, 'to': 42, '.': 35, ';': 35, 'he': 33, 'they': 32, 'of': 28, '’': 27, ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 words in text as of now\n",
    "fd_ct = FreqDist(prncss_wtk)\n",
    "fd_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The most common parts of text are filler and punctuation. First remove punctuation for better understanding of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1849"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of tokens before punctuation removal\n",
    "len(prncss_wtk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~’‘’’‘‘'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation = punctuation + '’' + '‘' + '’’' + '‘‘'\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation tokens from list\n",
    "for token in prncss_wtk:\n",
    "    if token in punctuation:\n",
    "        prncss_wtk.remove(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1644"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of tokens after punctuation removal\n",
    "len(prncss_wtk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation tokens from list again\n",
    "for token in prncss_wtk:\n",
    "    if token in punctuation:\n",
    "        prncss_wtk.remove(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1614"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of tokens after total punctuation removal\n",
    "len(prncss_wtk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 139, 'and': 78, 'to': 42, 'he': 33, 'they': 32, 'of': 28, 'in': 25, 'was': 24, 'all': 24, 'a': 22, ...})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 words in text as of now\n",
    "fd_ct = FreqDist(prncss_wtk)\n",
    "fd_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove english stop words from list\n",
    "eng_stopwords = stopwords.words('english')\n",
    "\n",
    "rm_count = 0\n",
    "prncss_new = []  #list to hold new words\n",
    "\n",
    "for token in prncss_wtk:\n",
    "    if token not in eng_stopwords:\n",
    "        prncss_new.append(token)\n",
    "    else: rm_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_stopwords[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removal count = 944\n",
      "final list length = 670\n"
     ]
    }
   ],
   "source": [
    "print(f\"removal count = {rm_count}\")\n",
    "print(f\"final list length = {len(prncss_new)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 words in text after tokenizing, punctuation removal, and stop words removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'soldier': 19, 'princesses': 17, 'said': 16, 'king': 15, 'twelve': 11, 'went': 11, 'came': 10, 'eldest': 10, 'one': 7, 'night': 7, ...})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 words in text after tokenizing, punctuation removal, and stop words removal.\n",
    "fd_ct = FreqDist(prncss_new)\n",
    "fd_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
